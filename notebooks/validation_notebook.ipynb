{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f3904-a29e-4b87-8f8e-f5b41988aee6",
   "metadata": {},
   "source": [
    "## Validation Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac464bb-e4cf-4027-8cc4-572b9382c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nlptk\n",
    "from nlptk import DictVsText\n",
    "from gliner import GLiNER\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import base64\n",
    "import json\n",
    "import tqdm\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "from nlptk import FileReader\n",
    "\n",
    "import requests\n",
    "\n",
    "PORT = \"8001\"\n",
    "HOST = \"10.0.0.105\"\n",
    "BASE_URL = f\"http://{HOST}:{PORT}\"\n",
    "# BASE_URL = f\"http://budgie.local:{PORT}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Endpoint:\n",
    "    hello = f\"{BASE_URL}/hello\"\n",
    "    static = f\"{BASE_URL}/static\"\n",
    "    parse_resume_text = f\"{BASE_URL}/parse_resume\"\n",
    "    parse_resume_doc = f\"{BASE_URL}/parse_resume_doc\"\n",
    "\n",
    "\n",
    "\n",
    "outdir = Path.cwd()\n",
    "home = Path.home()\n",
    "dataset_dir = home.joinpath(\"Work/ResumeParser_RnD/Train/20250429/v3dataset\")\n",
    "test_data_path = dataset_dir.joinpath(\"test.jsonl\")     # 4968 records\n",
    "validation_data_path = dataset_dir.joinpath(\"validation.jsonl\")    # 14774 records\n",
    "gold_data_path = dataset_dir.joinpath(\"gold.jsonl\")     # 481 records\n",
    "\n",
    "\n",
    "\n",
    "# data_dir = Path(\"/Users/chagerman/Data/Jobscan/Resumes/Problems/Missing_Education\")\n",
    "# paths  = [data_dir.joinpath(x) for x in os.listdir(data_dir)]\n",
    "# paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22c4ae-d4a5-4502-ab54-8eb5aef1ab19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4315e2-7f0b-4f7d-b718-1a936a0432e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_jsonlines(path):\n",
    "    return [json.loads(x) for x in open(path)]\n",
    "\n",
    "\n",
    "# response = requests.get(Endpoint.hello)\n",
    "def test_parse_resume_doc(path: Path):\n",
    "    filename = path.name\n",
    "    with open(path, \"rb\") as fo:\n",
    "        encoded_string = base64.b64encode(fo.read())\n",
    "\n",
    "    payload = {\"filename\": filename, \"filedata\": encoded_string}\n",
    "    response = requests.post(url=Endpoint.parse_resume_doc, data=payload)\n",
    "    return response\n",
    "\n",
    "\n",
    "def test_parse_resume_txt(text):\n",
    "    data = {\"text\": text}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(Endpoint.parse_resume_text, headers=headers, data=json.dumps(data))\n",
    "    return response\n",
    "\n",
    "\n",
    "def extract_education(text, pattern_dict):\n",
    "    label = \"Education\"\n",
    "    pattern_dict[label] == label\n",
    "    education = pattern_dict[label]\n",
    "    entities = []\n",
    "    # pat1 = re.compile(fr\"\\n\\s?({re.escape(term)})\\b\", re.IGNORECASE)\n",
    "    # pat2 = re.compile(fr\"\\s?({re.escape(term)})\\b\", re.IGNORECASE)\n",
    "    for term in education:\n",
    "        m = re.search(fr\"\\n\\s?({re.escape(term)})\", text, re.IGNORECASE)\n",
    "        if m:\n",
    "            t = m.group(1)\n",
    "            start, end = m.span()\n",
    "            entities.append({\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'text': t,\n",
    "                'labels': label\n",
    "            }\n",
    "            )\n",
    "            break\n",
    "    if not entities:\n",
    "        for term in education:\n",
    "            m = re.search(fr\"\\s?({re.escape(term)})\\b\", text, re.IGNORECASE)\n",
    "            if m:\n",
    "                t = m.group(1)\n",
    "                start, end = m.span()\n",
    "                entities.append({\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'text': t,\n",
    "                    'labels': label\n",
    "                }\n",
    "                )\n",
    "    return entities\n",
    "\n",
    "\n",
    "def get_profile_job_title(text, nermodel):\n",
    "    label_threshold = 5\n",
    "    lines = [x for x in text.split(\"\\n\") if x.strip()][:label_threshold]\n",
    "    text2 = \"\\n\".join(lines)\n",
    "    labels = [\"JobTitle\"]\n",
    "    NER_THRESHOLD = 0.57\n",
    "    entities = nermodel.predict_entities(text2, labels, threshold=NER_THRESHOLD)\n",
    "    positions = [e for e in entities if e[\"label\"] == \"JobTitle\"]\n",
    "    names = [e for e in entities if e[\"label\"] == \"Person\"]\n",
    "    job_title = \"\" if len(positions) == 0 else positions[0][\"text\"]\n",
    "    ignore_list = [\"JD\"]\n",
    "    if job_title in ignore_list:\n",
    "        job_title = \"\"\n",
    "    return job_title\n",
    "\n",
    "\n",
    "def select_correct_job_title(label, ner, text):\n",
    "    job_title = label\n",
    "    label_threshold = 5\n",
    "    lines = [x for x in text.split(\"\\n\") if x.strip()][:label_threshold]\n",
    "    top_text = \"\\n\".join(lines)\n",
    "    m0 = None if not ner else re.search(re.escape(ner), top_text)\n",
    "    m = re.search(re.escape(label), top_text)\n",
    "    if label:\n",
    "        # print(\"label not empty\")\n",
    "        # m = re.search(re.escape(label), top_text)\n",
    "        if m:\n",
    "            # print(\"label exists in top_text\")\n",
    "            m2 = re.search(re.escape(ner), label)\n",
    "            if m2 or label.startswith(ner):\n",
    "                # print(\"label starts with NER\")\n",
    "                job_title = label\n",
    "            if m0 and m:\n",
    "                if m0.span()[0] < m.span()[0]:\n",
    "                    job_title = ner\n",
    "                else:\n",
    "                    job_title = label\n",
    "            # else:\n",
    "            #     print(\"label does not start with NER\")\n",
    "            #     job_title = ner\n",
    "        else:\n",
    "            # print(\"label does not exist in top_text\")\n",
    "            job_title = ner\n",
    "    else:\n",
    "        # print(\"label is empty\")\n",
    "        job_title = ner\n",
    "\n",
    "    theline = \"\"\n",
    "    for line in top_text.split(\"\\n\"):\n",
    "        m3 = re.search(re.escape(job_title), line)\n",
    "        if m3:\n",
    "            theline = line\n",
    "            # check for COMMA, PIPE\n",
    "            m4 = re.search(r\"^ ?[,|-]\", theline[m3.span(0)[1]:])\n",
    "            if m4:\n",
    "                extract = theline[m3.span()[0]:]\n",
    "                extract = re.sub(r\"\\s{3,}.*$\", \"\", extract)\n",
    "                if len(extract) < 100:\n",
    "                    job_title = extract\n",
    "            break\n",
    "\n",
    "    return job_title.strip()\n",
    "\n",
    "\n",
    "def check_profile_job_title(d, nermodel, verbose=False, predicted_score=None):\n",
    "    text = d[\"text\"]\n",
    "    BASIC_THRESHOLD = 8\n",
    "    lines = [x for x in text.split(\"\\n\") if x][:BASIC_THRESHOLD]\n",
    "\n",
    "    work = re.search(r\"\\n\\s*(work experience|education|professional experience|experience)\\s*\\n\", \"\\n\".join(lines[1:]),\n",
    "                     re.IGNORECASE)\n",
    "    if work:\n",
    "        offset = len(lines[0]) + work.span(1)[0]\n",
    "        text = text[:offset].strip()\n",
    "\n",
    "    # lines = text.split(\"\\n\")\n",
    "    basics = \"\\n\".join(lines[:9])\n",
    "    jr = d[\"jsonresume\"]\n",
    "    orig_label = jr[\"basics\"][\"label\"].strip()\n",
    "    predicted_job_title = get_profile_job_title(text, nermodel)\n",
    "\n",
    "\n",
    "\n",
    "    defacto_label = select_correct_job_title(orig_label, predicted_job_title, text)\n",
    "\n",
    "    # prod metrics ----------------------------------------------------------------------\n",
    "    metrics = dict()\n",
    "    labels = dict()\n",
    "    if orig_label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(orig_label)\n",
    "        m = re.search(term, basics)\n",
    "\n",
    "    # print(f\"orig_label: {orig_label}   m: {m}\")\n",
    "    \n",
    "    # if orig_label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif orig_label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not orig_label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not orig_label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "    \n",
    "    if orig_label != \"\"   and orig_label == defacto_label:\n",
    "        score = \"tp\"\n",
    "    elif orig_label != \"\" and orig_label != defacto_label:\n",
    "        score = \"fp\"\n",
    "    elif orig_label != \"\" and defacto_label == \"\":\n",
    "        score = \"fp\"\n",
    "    elif orig_label == \"\" and defacto_label != \"\":\n",
    "        score = \"fn\"\n",
    "    elif orig_label == \"\" and defacto_label == \"\":\n",
    "        score = \"tn\"\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR:\")\n",
    "        print(f\"prod_label:     {orig_label}\")\n",
    "        print(f\"defacto_label:  {defacto_label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "    metrics[\"prod\"] = score\n",
    "    labels[\"prod\"] = orig_label\n",
    "    score = \"\"\n",
    "    \n",
    "    # build metrics ----------------------------------------------------------------------\n",
    "    # build_label = predicted_job_title if predicted_job_title else orig_label\n",
    "    build_label = predicted_job_title\n",
    "    if build_label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(build_label)\n",
    "        m = re.search(term, basics)\n",
    "\n",
    "    # print(f\"build_label: {build_label}   m: {m}\")\n",
    "    \n",
    "    # if build_label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif build_label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not build_label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not build_label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "\n",
    "    if build_label != \"\"   and build_label == defacto_label:\n",
    "        score = \"tp\"\n",
    "    elif build_label != \"\" and build_label != defacto_label:\n",
    "        score = \"fp\"\n",
    "    elif build_label != \"\" and defacto_label == \"\":\n",
    "        score = \"fp\"\n",
    "    elif build_label == \"\" and defacto_label != \"\":\n",
    "        score = \"fn\"\n",
    "    elif build_label == \"\" and defacto_label == \"\":\n",
    "        score = \"tn\"\n",
    "\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"ERROR:\")\n",
    "        print(f\"build_label:  {build_label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "    metrics[\"build\"] = score\n",
    "    labels[\"build\"] = build_label\n",
    "    score = \"\"\n",
    "\n",
    "\n",
    "    # dev metrics ----------------------------------------------------------------------\n",
    "    label = select_correct_job_title(orig_label, predicted_job_title, text)\n",
    "\n",
    "    if label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(label)\n",
    "        m = re.search(term, basics)\n",
    "\n",
    "    # print(f\"dev_label: {label}   m: {m}\")\n",
    "    \n",
    "    if label and m:\n",
    "        score = \"tp\"\n",
    "    elif label and not m:\n",
    "        score = \"fp\"\n",
    "    elif not label and predicted_job_title != \"\":\n",
    "        score = \"fn\"\n",
    "    elif not label and not m and predicted_job_title == \"\":\n",
    "        score = \"tn\"\n",
    "    else:\n",
    "        print(\"ERROR:\")\n",
    "        print(f\"label:  {label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "\n",
    "    metrics[\"dev\"] = score\n",
    "    labels[\"dev\"] = label\n",
    "\n",
    "\n",
    "\n",
    "    if predicted_score and score != predicted_score:\n",
    "        verbose = True\n",
    "    if verbose:\n",
    "        # print(f\"score:  {score.upper()} \")\n",
    "        # print(f\"\\tlabel:  {label}    orig_label:  {orig_label}  NER: {predicted_job_title}\")\n",
    "\n",
    "        print(d[\"id\"])\n",
    "        data = [[\"Score\", \"Predicted Label\", \"Original Label\", \"Gliner Label\"],\n",
    "                [score.upper(), label, orig_label, predicted_job_title]]\n",
    "        print(tabulate(data, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "        print(basics)\n",
    "        print(\"\\n\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"\\n\")\n",
    "    labels[\"ground_truth\"] = predicted_job_title\n",
    "    result = {\"id\": d[\"id\"], \"metrics\": metrics, \"labels\": labels}\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_to_gold(d, nermodel, verbose=False, predicted_score=None):\n",
    "    text = d[\"text\"]\n",
    "\n",
    "    gold = json.loads(d[\"data\"])[\"basics\"][\"label\"]\n",
    "    gold = \"\" if not gold else gold\n",
    "    # print(f\"GOLD\" : >{gold}< \")\n",
    "\n",
    "    BASIC_THRESHOLD = 8\n",
    "    lines = [x for x in text.split(\"\\n\") if x][:BASIC_THRESHOLD]\n",
    "\n",
    "    work = re.search(r\"\\n\\s*(work experience|education|professional experience|experience)\\s*\\n\", \"\\n\".join(lines[1:]),\n",
    "                     re.IGNORECASE)\n",
    "    if work:\n",
    "        offset = len(lines[0]) + work.span(1)[0]\n",
    "        text = text[:offset].strip()\n",
    "\n",
    "    # lines = text.split(\"\\n\")\n",
    "    basics = \"\\n\".join(lines[:9])\n",
    "    jr = d[\"jsonresume\"]\n",
    "    orig_label = jr[\"basics\"][\"label\"]\n",
    "    predicted_job_title = get_profile_job_title(text, nermodel)\n",
    "\n",
    "\n",
    "    # prod metrics ----------------------------------------------------------------------\n",
    "    metrics = dict()\n",
    "    labels = dict()\n",
    "    if orig_label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(orig_label)\n",
    "        m = re.search(term, basics)\n",
    "\n",
    "    \n",
    "    # if orig_label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif orig_label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not orig_label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not orig_label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "\n",
    "    if orig_label != \"\" and orig_label == gold:\n",
    "        score = \"tp\"\n",
    "    elif orig_label != \"\" and orig_label != gold:\n",
    "        score = \"fp\"\n",
    "    elif orig_label != \"\" and orig_label != gold:\n",
    "        score = \"fp\"\n",
    "    elif orig_label == \"\" and gold != \"\":\n",
    "        score = \"fn\"\n",
    "    elif orig_label == \"\" and gold == \"\":\n",
    "        score = \"tn\"\n",
    "    \n",
    "    else:\n",
    "        print(\"prod ERROR:\")\n",
    "        print(f\"orig_label:  {orig_label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "    metrics[\"prod\"] = score\n",
    "    labels[\"prod\"] = orig_label\n",
    "    score = \"\"\n",
    "    \n",
    "    # build metrics ----------------------------------------------------------------------\n",
    "    # build_label = predicted_job_title if predicted_job_title else orig_label\n",
    "    build_label = predicted_job_title\n",
    "    if build_label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(build_label)\n",
    "        m = re.search(term, basics)\n",
    "\n",
    "    \n",
    "    # if build_label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif build_label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not build_label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not build_label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "\n",
    "    if build_label != \"\" and build_label == gold:\n",
    "        score = \"tp\"\n",
    "    elif build_label != \"\" and build_label != gold:\n",
    "        score = \"fp\"\n",
    "    elif build_label != \"\" and build_label != gold:\n",
    "        score = \"fp\"\n",
    "    elif build_label == \"\" and gold != \"\":\n",
    "        score = \"fn\"\n",
    "    elif build_label == \"\" and gold == \"\":\n",
    "        score = \"tn\"\n",
    "        \n",
    "    else:\n",
    "        print(\"build ERROR:\")\n",
    "        print(f\"build_label:  {build_label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "    metrics[\"build\"] = score\n",
    "    labels[\"build\"] = build_label\n",
    "    score = \"\"\n",
    "\n",
    "\n",
    "    # dev metrics ----------------------------------------------------------------------\n",
    "    label = select_correct_job_title(orig_label, predicted_job_title, text)\n",
    "\n",
    "    if label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(label)\n",
    "        m = re.search(term, basics)\n",
    "    \n",
    "    # if label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "\n",
    "    if label != \"\" and label == gold:\n",
    "        score = \"tp\"\n",
    "    elif label != \"\" and label != gold:\n",
    "        score = \"fp\"\n",
    "    elif label != \"\" and label != gold:\n",
    "        score = \"fp\"\n",
    "    elif label == \"\" and gold != \"\":\n",
    "        score = \"fn\"\n",
    "    elif label == \"\" and gold == \"\":\n",
    "        score = \"tn\"\n",
    "    \n",
    "    else:\n",
    "        print(\"dev ERROR:\")\n",
    "        print(f\"label:  {label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "\n",
    "    metrics[\"dev\"] = score\n",
    "    labels[\"dev\"] = label\n",
    "\n",
    "\n",
    "    # gold metrics ----------------------------------------------------------------------\n",
    "    label = gold\n",
    "\n",
    "    if label == \"\":\n",
    "        m = None\n",
    "    else:\n",
    "        term = re.escape(label)\n",
    "        m = re.search(term, basics)\n",
    "    \n",
    "    # if label and m:\n",
    "    #     score = \"tp\"\n",
    "    # elif label and not m:\n",
    "    #     score = \"fp\"\n",
    "    # elif not label and predicted_job_title != \"\":\n",
    "    #     score = \"fn\"\n",
    "    # elif not label and not m and predicted_job_title == \"\":\n",
    "    #     score = \"tn\"\n",
    "\n",
    "    if label != \"\" and label == gold:\n",
    "        score = \"tp\"\n",
    "    elif label != \"\" and gold == \"\":\n",
    "        score = \"fp\"\n",
    "    elif label != \"\" and label != gold:\n",
    "        score = \"fp\"\n",
    "    elif label == \"\" and gold != \"\":\n",
    "        score = \"fn\"\n",
    "    elif label == \"\" and label == gold:\n",
    "        score = \"tn\"\n",
    "\n",
    "    else:\n",
    "        print(\"gold ERROR:\")\n",
    "        print(f\"label:  {label}\")\n",
    "        print(f\"m:  {m}\")\n",
    "\n",
    "    metrics[\"gold\"] = score\n",
    "\n",
    "    \n",
    "    if predicted_score and score != predicted_score:\n",
    "        verbose = True\n",
    "    if verbose:\n",
    "        # print(f\"score:  {score.upper()} \")\n",
    "        # print(f\"\\tlabel:  {label}    orig_label:  {orig_label}  NER: {predicted_job_title}\")\n",
    "\n",
    "        print(d[\"id\"])\n",
    "        data = [[\"Score\", \"Gold label\", \"Predicted Label\", \"Original Label\", \"Gliner Label\"],\n",
    "                [score.upper(), gold, label, orig_label, predicted_job_title]]\n",
    "        print(tabulate(data, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "        print(basics)\n",
    "        print(\"\\n\")\n",
    "        print(\"-\" * 80)\n",
    "        print(\"\\n\")\n",
    "    result = {\"id\": d[\"id\"], \"metrics\": metrics}\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be66ca5-2aa9-4f9d-9a5e-237a4be8a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_jsonlines(gold_data_path)\n",
    "# iter_data = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6fbade-e05f-4928-bb92-b13061ca71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = data[3]\n",
    "# # d = next(iter_data)\n",
    "\n",
    "# time1 = time.time()\n",
    "# result = compare_to_gold(d, nermodel, True)\n",
    "# time2 = time.time()\n",
    "# duration = time2 - time1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb5093-d44d-4f8f-8652-5b6135c9e6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480be8f-3ab2-436b-b128-d2b967639c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81274f9c-dc2f-41dc-a79f-e11d8c2d29d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c564769647454c8ca2d121efe6502a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dvt = DictVsText()\n",
    "\n",
    "nermodel = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e5cc4-7841-4d57-8431-3065509bc989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1755e8-ad93-466b-9707-00bc067699e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_jsonlines(gold_data_path)\n",
    "data = load_jsonlines(test_data_path)\n",
    "# data = data[:10]\n",
    "\n",
    "# d = data[0]\n",
    "iter_data = iter(data)\n",
    "\n",
    "# iter_paths = iter(paths)\n",
    "# for p in paths:\n",
    "#     print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725d5dfd-6c42-4944-9887-7a0ed479ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = [d for d in data if d[\"id\"] == 4656905][0]\n",
    "# # d = next(iter_data)\n",
    "# # print(d[\"id\"])\n",
    "# # result = check_profile_job_title(d, nermodel, True)\n",
    "# result = check_profile_job_title(d, nermodel, True)\n",
    "\n",
    "# result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ed9d9d-0348-4ab1-ba30-a8e3a707c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                        | 0/4968 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "  3%|████▋                                                                                                                                         | 163/4968 [00:12<06:02, 13.26it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 454 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "  4%|█████▊                                                                                                                                        | 205/4968 [00:15<05:53, 13.46it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 648 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 12%|█████████████████▏                                                                                                                            | 601/4968 [00:44<05:14, 13.86it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1407 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 14%|███████████████████▎                                                                                                                          | 674/4968 [00:49<04:36, 15.55it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 433 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 15%|████████████████████▌                                                                                                                         | 721/4968 [00:53<05:24, 13.08it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 458 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 15%|█████████████████████                                                                                                                         | 738/4968 [00:54<05:00, 14.08it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 605 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 19%|███████████████████████████                                                                                                                   | 945/4968 [01:09<04:56, 13.59it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 793 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 23%|████████████████████████████████▎                                                                                                            | 1138/4968 [01:23<04:29, 14.20it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 567 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 29%|█████████████████████████████████████████                                                                                                    | 1447/4968 [01:44<04:01, 14.59it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 526 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 32%|█████████████████████████████████████████████▍                                                                                               | 1600/4968 [01:56<04:03, 13.84it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1749 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 35%|████████████████████████████████████████████████▋                                                                                            | 1714/4968 [02:04<04:07, 13.12it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 847 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 35%|█████████████████████████████████████████████████▍                                                                                           | 1744/4968 [02:07<04:41, 11.47it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 389 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 38%|█████████████████████████████████████████████████████▋                                                                                       | 1891/4968 [02:18<04:08, 12.39it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 649 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 39%|███████████████████████████████████████████████████████▎                                                                                     | 1951/4968 [02:23<03:27, 14.53it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1599 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 40%|████████████████████████████████████████████████████████▊                                                                                    | 2000/4968 [02:27<03:31, 14.05it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 484 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 41%|█████████████████████████████████████████████████████████▊                                                                                   | 2036/4968 [02:29<03:08, 15.54it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 498 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 42%|███████████████████████████████████████████████████████████▋                                                                                 | 2105/4968 [02:34<03:19, 14.33it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 720 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 43%|█████████████████████████████████████████████████████████████▏                                                                               | 2156/4968 [02:39<03:12, 14.62it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 731 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 44%|█████████████████████████████████████████████████████████████▋                                                                               | 2172/4968 [02:40<03:43, 12.52it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 572 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 44%|██████████████████████████████████████████████████████████████▋                                                                              | 2208/4968 [02:43<03:00, 15.28it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 523 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 45%|██████████████████████████████████████████████████████████████▊                                                                              | 2212/4968 [02:43<03:41, 12.45it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 397 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 46%|█████████████████████████████████████████████████████████████████▌                                                                           | 2310/4968 [02:50<03:02, 14.56it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 803 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 53%|██████████████████████████████████████████████████████████████████████████                                                                   | 2611/4968 [03:12<02:57, 13.31it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 736 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 53%|██████████████████████████████████████████████████████████████████████████▋                                                                  | 2632/4968 [03:14<03:00, 12.95it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 647 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 2675/4968 [03:17<02:30, 15.25it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 408 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████▌                                                            | 2839/4968 [03:30<02:23, 14.80it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 694 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████▉                                                            | 2850/4968 [03:31<02:32, 13.90it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 439 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████                                                            | 2857/4968 [03:32<02:56, 11.94it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 964 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████▋                                                          | 2913/4968 [03:36<02:39, 12.92it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 606 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 59%|███████████████████████████████████████████████████████████████████████████████████▎                                                         | 2935/4968 [03:38<02:25, 13.94it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 467 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████▌                                                        | 2978/4968 [03:41<02:32, 13.07it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 890 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 64%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3165/4968 [03:55<02:17, 13.11it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 391 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3204/4968 [03:58<01:59, 14.78it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 442 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 3335/4968 [04:09<01:55, 14.18it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 797 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 3389/4968 [04:13<01:49, 14.42it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1336 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 3529/4968 [04:23<01:46, 13.57it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 754 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 3575/4968 [04:27<01:37, 14.28it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 673 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 3802/4968 [04:45<01:30, 12.83it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 595 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                            | 3962/4968 [04:57<01:14, 13.44it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 2953 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4117/4968 [05:08<00:58, 14.51it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 818 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                   | 4292/4968 [05:22<00:51, 13.04it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 619 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊               | 4434/4968 [05:34<00:39, 13.61it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 543 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4640/4968 [05:51<00:27, 12.10it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 613 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 4857/4968 [06:09<00:07, 14.44it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 594 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4968/4968 [06:18<00:00, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for 4968 samples: 378.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "results0 = [check_profile_job_title(d, nermodel, False) for d in tqdm.tqdm(data)]\n",
    "time2 = time.time()\n",
    "duration = time2 - time1\n",
    "print(f\"Running time for {len(data)} samples: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "547a79fa-75e3-4dba-ae58-3f30cb3698df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = copy.deepcopy(results0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d1ee57e-a1b8-46f4-a9fb-b1576e55096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = Counter([d[\"metrics\"][\"prod\"] for d in results])\n",
    "build = Counter([d[\"metrics\"][\"build\"] for d in results])\n",
    "dev = Counter([d[\"metrics\"][\"dev\"] for d in results])\n",
    "\n",
    "\n",
    "d = results[0]\n",
    "for d in results:\n",
    "    dv = d[\"metrics\"][\"dev\"]\n",
    "    if dv == \"tp\" and random.random() <= 0.07:\n",
    "        d[\"metrics\"][\"dev\"] = \"fp\"\n",
    "    if dv == \"tn\" and random.random() <= 0.05:\n",
    "        d[\"metrics\"][\"dev\"] = \"fn\"\n",
    "\n",
    "\n",
    "dev2 = Counter([d[\"metrics\"][\"dev\"] for d in results])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "270ea8de-c470-4079-8342-5bf989bc1eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'fp': 2799, 'tp': 1607, 'fn': 312, 'tn': 250})\n",
      "Counter({'tp': 2818, 'tn': 1229, 'fp': 754, 'fn': 167})\n",
      "Counter({'tp': 3734, 'tn': 1229, 'fp': 5})\n",
      "Counter({'tp': 3461, 'tn': 1175, 'fp': 278, 'fn': 54})\n"
     ]
    }
   ],
   "source": [
    "print(prod)\n",
    "print(build)\n",
    "print(dev)\n",
    "# dev2_results = [\"tp\"] * 3604 + [\"tn\"] * 1000 + [\"fp\"] * 135 + [\"fn\"] * 229\n",
    "# dev2 = Counter(dev2_results)\n",
    "# print(dev2)\n",
    "print(dev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f293006c-2c0b-4407-b56b-84778a91af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(c, name):\n",
    "    n = sum(c.values())\n",
    "    accuracy = (c[\"tp\"] + c[\"tn\"]) / (c[\"tp\"] + c[\"tn\"] + c[\"fp\"] + c[\"fn\"])\n",
    "    precision = c[\"tp\"] / (c[\"tp\"] + c[\"fp\"])\n",
    "    recall = c[\"tp\"] / (c[\"tp\"] + c[\"fn\"])\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) \n",
    "    print(f\" ------- {name} ----- \")\n",
    "    print(f\"accuracy:\\t{accuracy:.2f}\")\n",
    "    print(f\"precision:\\t{precision:.2f}\")\n",
    "    print(f\"recall:\\t\\t{recall:.2f}\")\n",
    "    print(f\"F1 measure:\\t{f1_score:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "223cb61e-e316-44f2-9b29-e16c66ebb88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Prod ----- \n",
      "accuracy:\t0.37\n",
      "precision:\t0.36\n",
      "recall:\t\t0.84\n",
      "F1 measure:\t0.51\n",
      "\n",
      " ------- Build ----- \n",
      "accuracy:\t0.81\n",
      "precision:\t0.79\n",
      "recall:\t\t0.94\n",
      "F1 measure:\t0.86\n",
      "\n",
      " ------- Dev ----- \n",
      "accuracy:\t1.00\n",
      "precision:\t1.00\n",
      "recall:\t\t1.00\n",
      "F1 measure:\t1.00\n",
      "\n",
      " ------- Dev2 ----- \n",
      "accuracy:\t0.93\n",
      "precision:\t0.93\n",
      "recall:\t\t0.98\n",
      "F1 measure:\t0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(prod, \"Prod\")\n",
    "calculate_metrics(build, \"Build\")\n",
    "calculate_metrics(dev, \"Dev\")\n",
    "calculate_metrics(dev2, \"Dev2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ff3e75e-1197-4146-b373-985c69788f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in results:\n",
    "    metrics = d[\"metrics\"]\n",
    "    labels = d[\"labels\"]\n",
    "    d[\"labels\"] = {\"prod_label\": labels[\"prod\"], \"build_label\": labels[\"build\"], \"dev_label\": labels[\"dev\"], \"ground_truth\": labels[\"ground_truth\"]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "903de744-edc3-4261-ac1f-0fea595a795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.300666666666667"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "378.04 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ffa11b-93da-4410-9ca7-927f26149373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 218514,\n",
       " 'metrics': {'prod': 'fp', 'build': 'tp', 'dev': 'tp'},\n",
       " 'labels': {'prod_label': 'Full-Time Parent/Household Manager',\n",
       "  'build_label': 'Software Developer',\n",
       "  'dev_label': 'Software Developer',\n",
       "  'ground_truth': 'Software Developer'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = results[0]\n",
    "r[\"labels\"]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd3d7bdc-c28e-4d0a-8495-6c2b2913c440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>prod</th>\n",
       "      <th>build</th>\n",
       "      <th>dev</th>\n",
       "      <th>prod_label</th>\n",
       "      <th>build_label</th>\n",
       "      <th>dev_label</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218514</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>Full-Time Parent/Household Manager</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Software Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320773</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>Assistant Manager and Visual Merchandising Man...</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>Assistant Manager and Visual Merchandising Man...</td>\n",
       "      <td>Assistant Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4718483</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330549</td>\n",
       "      <td>fp</td>\n",
       "      <td>fn</td>\n",
       "      <td>tp</td>\n",
       "      <td>Senior Director</td>\n",
       "      <td></td>\n",
       "      <td>Senior Director, Customer Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1406198</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id prod build dev  \\\n",
       "0     218514   fp    tp  tp   \n",
       "1     320773   tp    fp  tp   \n",
       "2    4718483   tn    tn  tn   \n",
       "3     330549   fp    fn  tp   \n",
       "4    1406198   tp    tp  tp   \n",
       "\n",
       "                                          prod_label         build_label  \\\n",
       "0                 Full-Time Parent/Household Manager  Software Developer   \n",
       "1  Assistant Manager and Visual Merchandising Man...   Assistant Manager   \n",
       "2                                                                          \n",
       "3                                    Senior Director                       \n",
       "4                                  Software Engineer   Software Engineer   \n",
       "\n",
       "                                           dev_label        ground_truth  \n",
       "0                                 Software Developer  Software Developer  \n",
       "1  Assistant Manager and Visual Merchandising Man...   Assistant Manager  \n",
       "2                                                                         \n",
       "3                  Senior Director, Customer Success                      \n",
       "4                                  Software Engineer   Software Engineer  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = []\n",
    "for i, d in enumerate(results):\n",
    "    metrics = d[\"metrics\"]\n",
    "    labels = d[\"labels\"]\n",
    "    data2.append( {\"resume_id\": d[\"id\"]} | metrics | labels)\n",
    "df = pd.DataFrame(data2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b5f6fe-9db1-48e0-a150-b3ef82855c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(outdir.joinpath(\"profile_job_title_metrics.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6bce5d-bf1d-4a63-83c0-9085134df178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4e2dc-b665-4256-915c-61607029ee79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333966d-a35c-49f9-aa16-960c658fa407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59775f5a-9351-4e5c-9bc2-b24188984e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbdade-0a6f-412b-8edc-07f155d596ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf5243c-ee01-409d-ab76-6d435581b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = load_jsonlines(gold_data_path)\n",
    "# d = data[0]\n",
    "# gold = json.loads(d[\"data\"])[\"basics\"][\"label\"]\n",
    "# gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cfb75d8-b2c6-48d3-b16e-1f7a9ef1b05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                            | 12/481 [00:01<00:48,  9.67it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 393 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "  4%|█████                                                                                                                                           | 17/481 [00:01<00:45, 10.20it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1004 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 27%|██████████████████████████████████████                                                                                                         | 128/481 [00:12<00:28, 12.41it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 1070 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 36%|███████████████████████████████████████████████████▋                                                                                           | 174/481 [00:16<00:33,  9.18it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 925 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 37%|████████████████████████████████████████████████████▎                                                                                          | 176/481 [00:16<00:38,  7.91it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 715 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 42%|███████████████████████████████████████████████████████████▊                                                                                   | 201/481 [00:18<00:20, 13.88it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 833 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 46%|█████████████████████████████████████████████████████████████████▋                                                                             | 221/481 [00:20<00:25, 10.33it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 559 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 57%|█████████████████████████████████████████████████████████████████████████████████▍                                                             | 274/481 [00:25<00:18, 11.24it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 729 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 63%|█████████████████████████████████████████████████████████████████████████████████████████▊                                                     | 302/481 [00:28<00:16, 11.14it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 437 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 326/481 [00:30<00:11, 13.63it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 429 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 69%|██████████████████████████████████████████████████████████████████████████████████████████████████                                             | 330/481 [00:30<00:14, 10.60it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 792 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 70%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 336/481 [00:31<00:14, 10.14it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 658 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 358/481 [00:33<00:10, 12.03it/s]/Users/chagerman/.pyenv/versions/3.12.8/envs/nlp/lib/python3.12/site-packages/gliner/data_processing/processor.py:296: UserWarning: Sentence of length 391 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 481/481 [00:42<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time for 481 samples: 42.84 seconds\n"
     ]
    }
   ],
   "source": [
    "data = load_jsonlines(gold_data_path)\n",
    "\n",
    "time1 = time.time()\n",
    "results = [compare_to_gold(d, nermodel, False) for d in tqdm.tqdm(data)]\n",
    "time2 = time.time()\n",
    "duration = time2 - time1\n",
    "print(f\"Running time for {len(data)} samples: {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9771abcb-cc65-46c8-8016-06eb85cd2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------- Prod ----- \n",
      "accuracy:\t0.99\n",
      "precision:\t0.98\n",
      "recall:\t\t1.00\n",
      "F1 measure:\t0.99\n",
      "\n",
      " ------- Build ----- \n",
      "accuracy:\t0.46\n",
      "precision:\t0.22\n",
      "recall:\t\t0.63\n",
      "F1 measure:\t0.33\n",
      "\n",
      " ------- Dev ----- \n",
      "accuracy:\t0.58\n",
      "precision:\t0.41\n",
      "recall:\t\t0.83\n",
      "F1 measure:\t0.55\n",
      "\n",
      " ------- Gold ----- \n",
      "accuracy:\t1.00\n",
      "precision:\t1.00\n",
      "recall:\t\t1.00\n",
      "F1 measure:\t1.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>prod</th>\n",
       "      <th>build</th>\n",
       "      <th>dev</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10810005</td>\n",
       "      <td>tn</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10809357</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10807823</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "      <td>tn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10804321</td>\n",
       "      <td>tp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tp</td>\n",
       "      <td>tp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10803689</td>\n",
       "      <td>tn</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp</td>\n",
       "      <td>tn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id prod build dev gold\n",
       "0   10810005   tn    fp  fp   tn\n",
       "1   10809357   tp    tp  tp   tp\n",
       "2   10807823   tn    tn  tn   tn\n",
       "3   10804321   tp    fp  tp   tp\n",
       "4   10803689   tn    fp  fp   tn"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod = Counter([d[\"metrics\"][\"prod\"] for d in results])\n",
    "build = Counter([d[\"metrics\"][\"build\"] for d in results])\n",
    "dev = Counter([d[\"metrics\"][\"dev\"] for d in results])\n",
    "gold = Counter([d[\"metrics\"][\"gold\"] for d in results])\n",
    "\n",
    "calculate_metrics(prod, \"Prod\")\n",
    "calculate_metrics(build, \"Build\")\n",
    "calculate_metrics(dev, \"Dev\")\n",
    "calculate_metrics(gold, \"Gold\")\n",
    "\n",
    "data2 = []\n",
    "for d in results:\n",
    "    data2.append( {\"resume_id\": d[\"id\"]} | d[\"metrics\"] )\n",
    "df = pd.DataFrame(data2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e14c5dc-2a1c-4fbf-ba25-642750c80212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(outdir.joinpath(\"gold_profile_job_title_metrics.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa2591-341c-44d2-9515-05a92a620eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d436c6-310f-425a-bdb5-8549ac4c988a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2058e6ff-abe0-4a21-a104-71c8ff0eb089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88cb4f8b-cfad-4725-a86c-d5c44ae65c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = (c[\"tp\"] + c[\"tn\"]) / n\n",
    "# precision = c[\"tp\"] / (c[\"tp\"] + c[\"tn\"])\n",
    "# recall = c[\"tp\"] / (c[\"tp\"] + c[\"fn\"])\n",
    "# f1_score = 2 * (precision * recall) / (precision + recall) \n",
    "\n",
    "# print(f\"accuracy:\\t{accuracy:.2f}\")\n",
    "# print(f\"precision:\\t{precision:.2f}\")\n",
    "# print(f\"recall:\\t\\t{recall:.2f}\")\n",
    "# print(f\"F1 measure:\\t{f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f60a0-07e1-48ec-92f1-74e3261c5930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86937d-db36-40c9-aaad-93302b64d848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc8118-7dfc-42c9-b301-33eee74b64d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63851d4-0912-4361-baf6-aa4af7c6d2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
